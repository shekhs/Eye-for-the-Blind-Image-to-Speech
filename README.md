# Eye-for-the-Blind
## Image-to-Speech
A deep learning model which can explain the contents of an image in the form of speech through caption generation with an attention mechanism on *[Flickr8K dataset](https://www.kaggle.com/adityajn105/flickr8k)*.

## Motivation
The project is an extended application of *[Show, Attend and Tell: Neural Image Caption Generation with Visual Attention](https://arxiv.org/abs/1502.03044)* paper.

## Dataset
*[Flickr8K dataset](https://www.kaggle.com/adityajn105/flickr8k)*
The dataset is taken from the Kaggle website and it consists of sentence-based image descriptions having a list of 8,000 images that are each paired with five different captions which provide clear descriptions of the salient entities and events of the image.

